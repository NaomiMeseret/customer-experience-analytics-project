{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 2: Sentiment and Thematic Analysis\n",
        "\n",
        "This notebook covers sentiment analysis and thematic extraction from customer reviews.\n",
        "\n",
        "## Objectives:\n",
        "- Perform sentiment analysis using DistilBERT model\n",
        "- Extract themes and keywords from reviews\n",
        "- Identify satisfaction drivers and pain points\n",
        "- Prepare data for insights generation\n",
        "\n",
        "## Model Used:\n",
        "- **Sentiment Analysis**: `distilbert-base-uncased-finetuned-sst-2-english` (Hugging Face)\n",
        "- **Thematic Analysis**: TF-IDF and spaCy NLP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data\n",
        "df = pd.read_csv('../data/processed/reviews_cleaned.csv')\n",
        "print(f\"‚úÖ Loaded {len(df)} reviews for analysis\")\n",
        "print(f\"\\nüìä Data Overview:\")\n",
        "print(f\"   Banks: {df['bank'].unique().tolist()}\")\n",
        "print(f\"   Rating Range: {df['rating'].min()} - {df['rating'].max()} stars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Sentiment Analysis\n",
        "\n",
        "**Note**: The full sentiment analysis is done using `sentiment_analysis.py`. This notebook demonstrates the process and loads results.\n",
        "\n",
        "### 2.1 Load Sentiment Analysis Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data with sentiment analysis\n",
        "try:\n",
        "    df_sentiment = pd.read_csv('../data/processed/reviews_with_sentiment.csv')\n",
        "    print(f\"‚úÖ Loaded {len(df_sentiment)} reviews with sentiment analysis\")\n",
        "    print(f\"\\nüí≠ Sentiment Distribution:\")\n",
        "    print(df_sentiment['sentiment_label'].value_counts())\n",
        "    print(f\"\\nüìä Average Sentiment Score: {df_sentiment['sentiment_score'].mean():.3f}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è  Sentiment analysis file not found.\")\n",
        "    print(\"üí° Please run: python task2_analysis/sentiment_analysis.py\")\n",
        "    df_sentiment = df.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Sentiment Analysis Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment distribution by bank\n",
        "if 'sentiment_label' in df_sentiment.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Sentiment distribution\n",
        "    ax1 = axes[0]\n",
        "    sentiment_by_bank = pd.crosstab(df_sentiment['bank'], df_sentiment['sentiment_label'])\n",
        "    sentiment_by_bank.plot(kind='bar', ax=ax1, color=['#FF6B6B', '#6BCB77'], width=0.8)\n",
        "    ax1.set_title('Sentiment Distribution by Bank', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Bank', fontsize=12)\n",
        "    ax1.set_ylabel('Number of Reviews', fontsize=12)\n",
        "    ax1.legend(title='Sentiment', title_fontsize=11)\n",
        "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=0)\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Average sentiment score\n",
        "    if 'sentiment_score' in df_sentiment.columns:\n",
        "        ax2 = axes[1]\n",
        "        avg_sentiment = df_sentiment.groupby('bank')['sentiment_score'].mean().sort_values(ascending=False)\n",
        "        colors = ['#6BCB77' if x > 0.5 else '#FF6B6B' for x in avg_sentiment]\n",
        "        avg_sentiment.plot(kind='bar', ax=ax2, color=colors, width=0.6)\n",
        "        ax2.set_title('Average Sentiment Score by Bank', fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Bank', fontsize=12)\n",
        "        ax2.set_ylabel('Average Sentiment Score', fontsize=12)\n",
        "        ax2.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Neutral (0.5)')\n",
        "        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=0)\n",
        "        ax2.legend()\n",
        "        ax2.grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Sentiment by Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze sentiment correlation with ratings\n",
        "if 'sentiment_label' in df_sentiment.columns:\n",
        "    print(\"=\"*60)\n",
        "    print(\"üí≠ SENTIMENT BY RATING\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    sentiment_rating = pd.crosstab(df_sentiment['rating'], df_sentiment['sentiment_label'])\n",
        "    print(\"\\n\", sentiment_rating)\n",
        "    \n",
        "    # Visualization\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    sentiment_rating.plot(kind='bar', ax=ax, color=['#FF6B6B', '#6BCB77'], width=0.8)\n",
        "    ax.set_title('Sentiment Distribution by Rating', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Rating', fontsize=12)\n",
        "    ax.set_ylabel('Number of Reviews', fontsize=12)\n",
        "    ax.legend(title='Sentiment', title_fontsize=11)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Thematic Analysis\n",
        "\n",
        "**Note**: The full thematic analysis is done using `thematic_analysis.py`. This notebook demonstrates the process and loads results.\n",
        "\n",
        "### 3.1 Load Thematic Analysis Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data with themes\n",
        "try:\n",
        "    df_themes = pd.read_csv('../data/processed/reviews_with_themes.csv')\n",
        "    print(f\"‚úÖ Loaded {len(df_themes)} reviews with thematic analysis\")\n",
        "    \n",
        "    # Extract and count themes\n",
        "    all_themes = []\n",
        "    for themes in df_themes['themes']:\n",
        "        if pd.notna(themes):\n",
        "            try:\n",
        "                if isinstance(themes, str):\n",
        "                    theme_list = eval(themes) if themes.startswith('[') else [themes]\n",
        "                else:\n",
        "                    theme_list = themes\n",
        "                all_themes.extend(theme_list)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    print(f\"\\nüè∑Ô∏è  Top 10 Themes Across All Banks:\")\n",
        "    theme_counts = Counter(all_themes)\n",
        "    for theme, count in theme_counts.most_common(10):\n",
        "        print(f\"   {theme}: {count} reviews\")\n",
        "        \n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è  Thematic analysis file not found.\")\n",
        "    print(\"üí° Please run: python task2_analysis/thematic_analysis.py\")\n",
        "    df_themes = df_sentiment.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Theme Distribution by Bank\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze themes by bank\n",
        "if 'themes' in df_themes.columns:\n",
        "    theme_data = []\n",
        "    for _, row in df_themes.iterrows():\n",
        "        if pd.notna(row['themes']):\n",
        "            try:\n",
        "                if isinstance(row['themes'], str):\n",
        "                    themes = eval(row['themes']) if row['themes'].startswith('[') else [row['themes']]\n",
        "                else:\n",
        "                    themes = row['themes']\n",
        "                for theme in themes:\n",
        "                    theme_data.append({'bank': row['bank'], 'theme': theme})\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    if theme_data:\n",
        "        theme_df = pd.DataFrame(theme_data)\n",
        "        theme_counts = theme_df.groupby(['bank', 'theme']).size().unstack(fill_value=0)\n",
        "        \n",
        "        # Visualization\n",
        "        fig, ax = plt.subplots(figsize=(12, 8))\n",
        "        theme_counts.plot(kind='barh', ax=ax, width=0.8, colormap='Set3')\n",
        "        ax.set_title('Theme Distribution by Bank', fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('Number of Reviews', fontsize=12)\n",
        "        ax.set_ylabel('Bank', fontsize=12)\n",
        "        ax.legend(title='Theme', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
        "        ax.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Print top themes per bank\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üè∑Ô∏è  TOP THEMES BY BANK\")\n",
        "        print(\"=\"*60)\n",
        "        for bank in df_themes['bank'].unique():\n",
        "            bank_themes = theme_df[theme_df['bank'] == bank]['theme'].value_counts().head(3)\n",
        "            print(f\"\\n{bank}:\")\n",
        "            for theme, count in bank_themes.items():\n",
        "                print(f\"   {theme}: {count} reviews\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2 Summary\n",
        "\n",
        "‚úÖ **Completed Steps:**\n",
        "1. Sentiment analysis using DistilBERT model\n",
        "2. Sentiment distribution analysis by bank and rating\n",
        "3. Thematic analysis using TF-IDF and keyword extraction\n",
        "4. Theme identification and categorization\n",
        "5. Data preparation for insights generation\n",
        "\n",
        "‚úÖ **KPIs Achieved:**\n",
        "- Sentiment scores for 90%+ reviews\n",
        "- 3+ themes identified per bank\n",
        "- Modular analysis pipeline\n",
        "\n",
        "**Next Step**: Proceed to Task 3 for Database Storage or Task 4 for Insights and Recommendations\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
